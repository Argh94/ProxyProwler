import requests
import re
import random
import time
import logging
import socket
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import pytz
import jdatetime
import timeit
import json

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
]

def get_random_user_agent():
    return random.choice(USER_AGENTS)

def check_proxy_status(server, port, timeout=3):
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((server, int(port)))
        sock.close()
        if result == 0:
            logging.info(f"Proxy {server}:{port} is online")
            return True
        else:
            logging.warning(f"Proxy {server}:{port} is offline or unreachable")
            return False
    except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
        logging.error(f"Error checking proxy {server}:{port}: {e}")
        return False

def measure_proxy_ping(server, port, timeout=3, tries=1):
    total_time = 0
    successful_tries = 0
    for _ in range(tries):
        start_time = timeit.default_timer()
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((server, int(port)))
            sock.close()
            if result == 0:
                elapsed = (timeit.default_timer() - start_time) * 1000 
                total_time += elapsed
                successful_tries += 1
                logging.debug(f"Ping for {server}:{port}: {elapsed:.2f}ms")
            else:
                logging.warning(f"Ping failed for {server}:{port}")
        except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
            logging.error(f"Ping error for {server}:{port}: {e}")
        time.sleep(0.2)
    if successful_tries > 0:
        average_ping = total_time / successful_tries
        logging.info(f"Average ping for {server}:{port}: {average_ping:.2f}ms")
        return average_ping
    return None

def fetch_proxies_from_url(url, proxy_type, max_proxies=50):
    proxies = []
    headers = {'User-Agent': get_random_user_agent()}
    pattern = r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}$'
    
    try:
        logging.info(f"Fetching {proxy_type} proxies from {url}")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        proxy_checks = []
        
        content_type = response.headers.get('content-type', '')
        if 'application/json' in content_type:
            try:
                data = response.json()
                logging.info(f"Processing JSON content from {url}")
                for item in data[:max_proxies]:
                    ip = item.get('ip')
                    port = item.get('port')
                    if ip and port:
                        proxy = f"{ip}:{port}"
                        if re.match(pattern, proxy):
                            server, port = proxy.split(':')
                            proxy_checks.append((proxy, server, port))
                        else:
                            logging.debug(f"Invalid {proxy_type} proxy format in JSON: {proxy}")
                    else:
                        logging.debug(f"Missing ip or port in JSON item: {item}")
            except json.JSONDecodeError as e:
                logging.error(f"Invalid JSON format from {url}: {e}")
                return []
        else:
            lines = response.text.splitlines()
            for line in lines[:max_proxies]:
                line = line.strip()
                if not line:
                    continue
                if re.match(pattern, line):
                    server, port = line.split(':')
                    proxy_checks.append((line, server, port))
                else:
                    logging.debug(f"Invalid {proxy_type} proxy format: {line}")
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_proxy = {executor.submit(check_proxy_status, server, port): (proxy, server, port) for proxy, server, port in proxy_checks}
            for future in as_completed(future_to_proxy):
                proxy, server, port = future_to_proxy[future]
                try:
                    if future.result():
                        ping = measure_proxy_ping(server, port)
                        if ping is not None:
                            proxies.append((proxy, ping))
                            logging.info(f"Valid and online {proxy_type} proxy: {proxy} (Ping: {ping:.2f}ms)")
                        else:
                            logging.warning(f"Skipping {proxy_type} proxy {proxy} due to ping failure")
                    else:
                        logging.warning(f"Skipping offline {proxy_type} proxy: {proxy}")
                except Exception as e:
                    logging.error(f"Error checking {proxy_type} proxy {proxy}: {e}")
                time.sleep(0.1)
        
        logging.debug(f"Proxies fetched for {proxy_type}: {proxies}")
        return proxies
    except requests.RequestException as e:
        logging.error(f"HTTP error fetching {url}: {e}")
        return []

def save_proxies_to_file(proxies, proxy_type):
    output_dir = os.getenv('OUTPUT_DIR', '/tmp/proxies')
    filename = f"{output_dir}/{proxy_type}.txt"
    try:
        unique_proxies = list(set(proxy[0] for proxy in proxies))
        logging.debug(f"Unique proxies for {proxy_type}: {unique_proxies}")
        os.makedirs(output_dir, exist_ok=True)
        with open(filename, 'w', encoding='utf-8') as file:
            if unique_proxies:
                for proxy in unique_proxies:
                    file.write(proxy + '\n')
            else:
                file.write('')
        logging.info(f"Saved {len(unique_proxies)} unique {proxy_type} proxies to {filename}")
        if os.path.exists(filename):
            logging.info(f"Confirmed: {filename} exists in {output_dir}")
        else:
            logging.error(f"Failed: {filename} was not created")
        return proxies
    except IOError as e:
        logging.error(f"Error writing to {filename}: {e}")
        return []

def update_readme(proxy_dict):
    try:
        utc_now = datetime.now(pytz.UTC)
        iran_tz = pytz.timezone('Asia/Tehran')
        iran_now = utc_now.astimezone(iran_tz)
        jalali_date = jdatetime.datetime.fromgregorian(datetime=iran_now)
        update_time_iran = jalali_date.strftime('%H:%M %d-%m-%Y')
        logging.info(f"Updating README with Iranian timestamp: {update_time_iran}")

        proxy_counts = {ptype: len(proxies) for ptype, proxies in proxy_dict.items()}
        
        table_rows = ""
        for proxy_type, proxies in proxy_dict.items():
            table_rows += f"\n<div align=\"center\">\n\n### ğŸ”— {proxy_type} Proxies ({proxy_counts[proxy_type]} Active)\n\n"
            table_rows += "| # | Ø³Ø±ÙˆØ± (Server) | Ù¾ÙˆØ±Øª (Port) | Ù¾ÛŒÙ†Ú¯ (Ping) | ÙˆØ¶Ø¹ÛŒØª (Status) |\n"
            table_rows += "|---|---------------|-------------|-------------|----------------|\n"
            sample_proxies = random.sample(proxies, min(5, len(proxies))) if proxies else []
            if not sample_proxies:
                table_rows += f"| - | - | - | - | Ù‡ÛŒÚ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ |\n"
            for i, (proxy, ping) in enumerate(sample_proxies, 1):
                server, port = proxy.split(':')
                status = "âœ… ÙØ¹Ø§Ù„" if ping is not None else "âŒ ØºÛŒØ±ÙØ¹Ø§Ù„"
                table_rows += f"| {i} | `{server}` | `{port}` | {ping:.2f}ms | {status} |\n"
            table_rows += "\n</div>\n"

        readme_content = f"""# ğŸ¦ ProxyProwler

<div align="center">
  <img src="https://img.shields.io/badge/ProxyProwler-v1.0-blueviolet?style=for-the-badge&logo=python" alt="ProxyProwler Version">
  <img src="https://img.shields.io/badge/Python-3.9%2B-blue?style=flat-square&logo=python" alt="Python Version">
  <img src="https://img.shields.io/github/workflow/status/Argh94/ProxyProwler/ProxyProwler?label=Workflow&style=flat-square" alt="Workflow Status">
  <img src="https://img.shields.io/github/license/Argh94/ProxyProwler?label=License&style=flat-square" alt="License">
</div>

<div align="center">
  <p><strong>Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:</strong> {update_time_iran} (Ø¨Ù‡ ÙˆÙ‚Øª Ø§ÛŒØ±Ø§Ù†)</p>
  <p><strong>ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ:</strong> ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ <code>SOCKS5.txt</code>, <code>SOCKS4.txt</code>, <code>HTTPS.txt</code>, Ùˆ <code>requirements.txt</code> Ø¯Ø± <a href="https://github.com/Argh94/ProxyProwler/releases">Ø¨Ø®Ø´ Releases</a> Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù‡Ø³ØªÙ†Ø¯.</p>
</div>

**ProxyProwler** ÛŒÚ© Ø§Ø¨Ø²Ø§Ø± Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ùˆ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒØŒ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ **SOCKS5**ØŒ **SOCKS4** Ùˆ **HTTPS** Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³Øª. Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø§ Ù‡Ø¯Ù Ø§Ø±Ø§Ø¦Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ùˆ Ø¨Ø§Ú©ÛŒÙÛŒØª Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ú¯Ø§Ù† Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

---

## ğŸ¯ Ú†Ø±Ø§ ProxyProwlerØŸ
- ğŸŒ **Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±**: Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ² Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
- âš¡ **Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª**: ÙˆØ¶Ø¹ÛŒØª Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù† Ùˆ Ù¾ÛŒÙ†Ú¯ Ù‡Ø± Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
- ğŸ—‘ **Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§**: Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
- ğŸ“Š **Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø±ØªØ¨**: Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
- ğŸ–¥ **Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ**: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± README Ø¨Ø§ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

---

## ğŸš€ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
- **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…ØªÙ†ÙˆØ¹**: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ JSON.
- **Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ThreadPoolExecutor Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§.
- **Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒÙ†Ú¯**: Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒÙ†Ú¯ Ù‡Ø± Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§.
- **Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„**: ÙÙ‚Ø· Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
- **Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯Ø³ØªÛŒ**: Ø§Ø² Ø·Ø±ÛŒÙ‚ GitHub Actions Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.

---

## ğŸ“‹ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§
Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØ¯:
- ğŸ **Ù¾Ø§ÛŒØªÙˆÙ† 3.9 ÛŒØ§ Ø¨Ø§Ù„Ø§ØªØ±**
- ğŸ“¦ **Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²**:
  - `requests`
  - `pytz`
  - `jdatetime`
- Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§:
  ```bash
  pip install -r requirements.txt

## ğŸ›  Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
1. **Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§**:
   - ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ <code>SOCKS5.txt</code>, <code>SOCKS4.txt</code>, <code>HTTPS.txt</code>, Ùˆ <code>requirements.txt</code> Ø±Ø§ Ø§Ø² <a href="https://github.com/model7855/ProxyProwler/releases">Ø¨Ø®Ø´ Releases</a> Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.
2. **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§**:
   - Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ (Ù…Ø«Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±Ù‡Ø§ ÛŒØ§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡) ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.
3. **Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ**:
   - Workflow Ø±Ø§ Ø§Ø² ØªØ¨ <strong>Actions</strong> Ø¯Ø± GitHub Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯ ØªØ§ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´ÙˆÙ†Ø¯.

---

## ğŸŒ Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ
ProxyProwler Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ø²ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

<div align="center">

| Ù…Ù†Ø¨Ø¹ | Ù†ÙˆØ¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ | Ù„ÛŒÙ†Ú© |
|------|-------------|------|
| OpenProxyList | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/roosterkid/openproxylist) |
| KangProxy | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/officialputuid/KangProxy) |
| Proxifly | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/proxifly/free-proxy-list) |
| Hookzof | SOCKS5 | [GitHub](https://github.com/hookzof/socks5_list) |
| TheSpeedX | SOCKS5, SOCKS4 | [GitHub](https://github.com/TheSpeedX/SOCKS-List) |
| Jetkai | SOCKS5 | [GitHub](https://github.com/jetkai/proxy-list) |
| ProxyScrape | SOCKS5 | [API](https://api.proxyscrape.com) |

</div>

---

## ğŸ“ˆ Ù†Ù…ÙˆÙ†Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§
Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ (Ø­Ø¯Ø§Ú©Ø«Ø± Ûµ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¹) Ø±Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù¾ÛŒÙ†Ú¯ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¢Ù†â€ŒÙ‡Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯:

{table_rows}

> **ğŸ’¡ Ù†Ú©ØªÙ‡**: Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù„ÛŒØ³Øª Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ØŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø±Ø§ Ø§Ø² <a href="https://github.com/Argh94/ProxyProwler/releases">Ø¨Ø®Ø´ Releases</a> Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.

---

## ğŸ›  Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ
Ø§Ú¯Ø± Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ÛŒØ¯ØŒ Ø§ÛŒÙ† Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯:
- **Ø®Ø·Ø§ÛŒ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§**: Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ `requirements.txt` Ø±Ø§ Ø§Ø² Releases Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯.
- **Ø¹Ø¯Ù… ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ**: Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ GitHub Actions Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ Ø¢ÛŒØ§ Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù‡Ø³ØªÙ†Ø¯.
- **Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„**: Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…ÙˆÙ‚ØªØ§Ù‹ Ø§Ø² Ø¯Ø³ØªØ±Ø³ Ø®Ø§Ø±Ø¬ Ø´ÙˆÙ†Ø¯. Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª `proxy_urls` Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.

---

## ğŸ¤ Ù…Ø´Ø§Ø±Ú©Øª Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡
Ù…Ø§ Ø§Ø² Ù…Ø´Ø§Ø±Ú©Øª Ø´Ù…Ø§ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…! Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ProxyProwler:
1. Ù…Ø®Ø²Ù† Ø±Ø§ ÙÙˆØ±Ú© Ú©Ù†ÛŒØ¯.
2. ØªØºÛŒÛŒØ±Ø§Øª Ø®ÙˆØ¯ (Ù…Ø«Ù„ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø¯) Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒØ¯.
3. Pull Request Ø¨ÙØ±Ø³ØªÛŒØ¯.
Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ **Issues** Ø¯Ø± GitHub Ù…Ø·Ø±Ø­ Ú©Ù†ÛŒØ¯.

---

## ğŸ“œ Ù„Ø§ÛŒØ³Ù†Ø³
Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ­Øª **[Ù„Ø§ÛŒØ³Ù†Ø³ MIT](https://github.com/Argh94/ProxyProwler/blob/main/Files/LISENSE)** Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø´Ù…Ø§ Ø¢Ø²Ø§Ø¯ÛŒØ¯ Ú©Ù‡ Ø§Ø² Ú©Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ØŒ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯ Ùˆ Ø¨Ù‡ Ø§Ø´ØªØ±Ø§Ú© Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯.

---

<div align="center">
  <p><strong>ğŸš€ ProxyProwler</strong> - Ø¨Ø§ Ù‚Ø¯Ø±Øª Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„!</p>
  <p>Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª ÛŒØ§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§ØªØŒ Ø¯Ø± <a href="https://github.com/Argh94/ProxyProwler/issues">GitHub</a> Ø¨Ø§ Ù…Ø§ Ø¯Ø± ØªÙ…Ø§Ø³ Ø¨Ø§Ø´ÛŒØ¯.</p>
</div>
"""
        filename = "README.md"
        with open(filename, 'w', encoding='utf-8') as file:
            file.write(readme_content)
        logging.info(f"Successfully updated {filename}")
        if os.path.exists(filename):
            logging.info(f"Confirmed: {filename} exists in the repository root")
        else:
            logging.error(f"Failed: {filename} was not created")
    except Exception as e:
        logging.error(f"Error updating {filename}: {e}")

if __name__ == "__main__":
    proxy_urls = {
        'SOCKS5': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS5_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks5/socks5.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks5/data.txt",
            "https://raw.githubusercontent.com/hookzof/socks5_list/master/tg/socks.json",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt",
            "https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-socks5.txt",
            "https://api.proxyscrape.com/v3/free-proxy-list/get?request=displayproxies&proxytype=socks5"
        ],
        'SOCKS4': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS4_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks4/socks4.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks4/data.txt",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks4.txt"
        ],
        'HTTPS': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/https/https.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/http/data.txt"
        ]
    }
    proxy_type = sys.argv[1] if len(sys.argv) > 1 else None
    proxy_dict = {}
    if proxy_type and proxy_type in proxy_urls:
        all_proxies = []
        for url in proxy_urls[proxy_type]:
            proxies = fetch_proxies_from_url(url, proxy_type)
            all_proxies.extend(proxies)
        proxy_dict[proxy_type] = all_proxies
        save_proxies_to_file(all_proxies, proxy_type)
    else:
        for proxy_type, urls in proxy_urls.items():
            all_proxies = []
            for url in urls:
                proxies = fetch_proxies_from_url(url, proxy_type)
                all_proxies.extend(proxies)
            proxy_dict[proxy_type] = all_proxies
            save_proxies_to_file(all_proxies, proxy_type)

    logging.debug(f"Final proxy_dict: {proxy_dict}")
    update_readme(proxy_dict)
