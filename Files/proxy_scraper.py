import requests
import re
import random
import time
import logging
import socket
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import pytz
import jdatetime
import timeit
import json

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
]

def get_random_user_agent():
    return random.choice(USER_AGENTS)

def check_proxy_status(server, port, timeout=3):
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((server, int(port)))
        sock.close()
        if result == 0:
            logging.info(f"Proxy {server}:{port} is online")
            return True
        else:
            logging.warning(f"Proxy {server}:{port} is offline or unreachable")
            return False
    except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
        logging.error(f"Error checking proxy {server}:{port}: {e}")
        return False

def measure_proxy_ping(server, port, timeout=3, tries=1):
    total_time = 0
    successful_tries = 0
    for _ in range(tries):
        start_time = timeit.default_timer()
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((server, int(port)))
            sock.close()
            if result == 0:
                elapsed = (timeit.default_timer() - start_time) * 1000 
                total_time += elapsed
                successful_tries += 1
                logging.debug(f"Ping for {server}:{port}: {elapsed:.2f}ms")
            else:
                logging.warning(f"Ping failed for {server}:{port}")
        except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
            logging.error(f"Ping error for {server}:{port}: {e}")
        time.sleep(0.2)
    if successful_tries > 0:
        average_ping = total_time / successful_tries
        logging.info(f"Average ping for {server}:{port}: {average_ping:.2f}ms")
        return average_ping
    return None

def fetch_proxies_from_url(url, proxy_type, max_proxies=50):
    proxies = []
    headers = {'User-Agent': get_random_user_agent()}
    pattern = r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}$'
    
    try:
        logging.info(f"Fetching {proxy_type} proxies from {url}")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        proxy_checks = []
        
        content_type = response.headers.get('content-type', '')
        if 'application/json' in content_type:
            try:
                data = response.json()
                logging.info(f"Processing JSON content from {url}")
                for item in data[:max_proxies]:
                    ip = item.get('ip')
                    port = item.get('port')
                    if ip and port:
                        proxy = f"{ip}:{port}"
                        if re.match(pattern, proxy):
                            server, port = proxy.split(':')
                            proxy_checks.append((proxy, server, port))
                        else:
                            logging.debug(f"Invalid {proxy_type} proxy format in JSON: {proxy}")
                    else:
                        logging.debug(f"Missing ip or port in JSON item: {item}")
            except json.JSONDecodeError as e:
                logging.error(f"Invalid JSON format from {url}: {e}")
                return []
        else:
            lines = response.text.splitlines()
            for line in lines[:max_proxies]:
                line = line.strip()
                if not line:
                    continue
                if re.match(pattern, line):
                    server, port = line.split(':')
                    proxy_checks.append((line, server, port))
                else:
                    logging.debug(f"Invalid {proxy_type} proxy format: {line}")
        
        with ThreadPoolExecutor(max_workers=30) as executor:
            future_to_proxy = {executor.submit(check_proxy_status, server, port): (proxy, server, port) for proxy, server, port in proxy_checks}
            for future in as_completed(future_to_proxy):
                proxy, server, port = future_to_proxy[future]
                try:
                    if future.result():
                        ping = measure_proxy_ping(server, port)
                        if ping is not None:
                            proxies.append((proxy, ping))
                            logging.info(f"Valid and online {proxy_type} proxy: {proxy} (Ping: {ping:.2f}ms)")
                        else:
                            logging.warning(f"Skipping {proxy_type} proxy {proxy} due to ping failure")
                    else:
                        logging.warning(f"Skipping offline {proxy_type} proxy: {proxy}")
                except Exception as e:
                    logging.error(f"Error checking {proxy_type} proxy {proxy}: {e}")
                time.sleep(0.1)
        
        logging.debug(f"Proxies fetched for {proxy_type}: {proxies}")
        return proxies
    except requests.RequestException as e:
        logging.error(f"HTTP error fetching {url}: {e}")
        return []

def save_proxies_to_file(proxies, proxy_type):
    output_dir = os.getenv('OUTPUT_DIR', 'Files')
    filename = f"{output_dir}/{proxy_type}.txt"
    try:
        unique_proxies = list(set(proxy[0] for proxy in proxies))
        logging.debug(f"Unique proxies for {proxy_type}: {unique_proxies}")
        os.makedirs(output_dir, exist_ok=True)
        with open(filename, 'w', encoding='utf-8') as file:
            if unique_proxies:
                for proxy in unique_proxies:
                    file.write(proxy + '\n')
            else:
                file.write('')
        logging.info(f"Saved {len(unique_proxies)} unique {proxy_type} proxies to {filename}")
        if os.path.exists(filename):
            logging.info(f"Confirmed: {filename} exists in {output_dir}")
        else:
            logging.error(f"Failed: {filename} was not created")
        return proxies
    except IOError as e:
        logging.error(f"Error writing to {filename}: {e}")
        return []

def update_readme(proxy_dict):
    try:
        utc_now = datetime.now(pytz.UTC)
        iran_tz = pytz.timezone('Asia/Tehran')
        iran_now = utc_now.astimezone(iran_tz)
        jalali_date = jdatetime.datetime.fromgregorian(datetime=iran_now)
        update_time_iran = jalali_date.strftime('%H:%M %d-%m-%Y')
        logging.info(f"Updating README with Iranian timestamp: {update_time_iran}")

        proxy_counts = {ptype: len(proxies) for ptype, proxies in proxy_dict.items()}
        
        table_rows = ""
        for proxy_type, proxies in proxy_dict.items():
            logging.debug(f"Processing {proxy_type} with {len(proxies)} proxies for README")
            table_rows += f"\n### üîó {proxy_type} Proxies ({proxy_counts[proxy_type]} Active)\n"
            table_rows += "| # | ÿ≥ÿ±Ÿàÿ± (Server) | ŸæŸàÿ±ÿ™ (Port) | Ÿæ€åŸÜ⁄Ø (Ping) | Ÿàÿ∂ÿπ€åÿ™ |\n"
            table_rows += "|---|---------------|-------------|-------------|-------|\n"
            sample_proxies = random.sample(proxies, min(5, len(proxies))) if proxies else []
            if not sample_proxies:
                table_rows += f"| - | - | - | - | Ÿá€å⁄Ü Ÿæÿ±Ÿà⁄©ÿ≥€å ŸÅÿπÿßŸÑ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ |\n"
            for i, (proxy, ping) in enumerate(sample_proxies, 1):
                server, port = proxy.split(':')
                table_rows += f"| {i} | `{server}` | `{port}` | {ping:.2f}ms | ‚úÖ ŸÅÿπÿßŸÑ |\n"

        readme_content = f"""# ü¶Å ProxyProwler

<div align="center">
  <img src="https://img.shields.io/badge/ProxyProwler-v1.0-blueviolet?style=for-the-badge&logo=python" alt="ProxyProwler Version">
  <img src="https://img.shields.io/badge/Python-3.9%2B-blue?style=flat-square&logo=python" alt="Python Version">
  <img src="https://img.shields.io/github/workflow/status/Argh94/ProxyProwler/ProxyProwler?label=Workflow&style=flat-square" alt="Workflow Status">
  <img src="https://img.shields.io/github/license/Argh94/ProxyProwler?label=License&style=flat-square" alt="License">
</div>

**ÿ¢ÿÆÿ±€åŸÜ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å:** {update_time_iran} (ÿ®Ÿá ŸàŸÇÿ™ ÿß€åÿ±ÿßŸÜ)

**ŸÅÿß€åŸÑ‚ÄåŸáÿß€å Ÿæÿ±Ÿà⁄©ÿ≥€å**: ŸÅÿß€åŸÑ‚ÄåŸáÿß€å `SOCKS5.txt`, `SOCKS4.txt`, `HTTPS.txt`, Ÿà `requirements.txt` ÿØÿ± [ÿ®ÿÆÿ¥ Releases](https://github.com/Argh94/ProxyProwler/releases) ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ Ÿáÿ≥ÿ™ŸÜÿØ.

**ProxyProwler** €å⁄© ÿßÿ®ÿ≤ÿßÿ± ŸÇÿØÿ±ÿ™ŸÖŸÜÿØ Ÿà ÿÆŸàÿØ⁄©ÿßÿ± Ÿæÿß€åÿ™ŸàŸÜ ÿ®ÿ±ÿß€å ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€åÿå ÿ®ÿ±ÿ±ÿ≥€å Ÿà ŸÖÿØ€åÿ±€åÿ™ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å **SOCKS5**ÿå **SOCKS4** Ÿà **HTTPS** ÿßÿ≤ ŸÖŸÜÿßÿ®ÿπ ÿπŸÖŸàŸÖ€å ÿßÿ≥ÿ™. ÿß€åŸÜ Ÿæÿ±Ÿà⁄òŸá ÿ®ÿß ŸáÿØŸÅ ÿßÿ±ÿßÿ¶Ÿá Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ŸÅÿπÿßŸÑ Ÿà ÿ®ÿß⁄©€åŸÅ€åÿ™ ÿ®ÿ±ÿß€å ÿ™Ÿàÿ≥ÿπŸá‚ÄåÿØŸáŸÜÿØ⁄ØÿßŸÜ Ÿà ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ∑ÿ±ÿßÿ≠€å ÿ¥ÿØŸá Ÿà ÿÆÿ±Ÿàÿ¨€å‚ÄåŸáÿß ÿ±ÿß ÿØÿ± ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ŸÖÿ±ÿ™ÿ® ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äå⁄©ŸÜÿØ.

## üéØ ⁄Üÿ±ÿß ProxyProwlerÿü
- **ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€å ÿÆŸàÿØ⁄©ÿßÿ±**: Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿßÿ≤ ŸÖŸÜÿßÿ®ÿπ ŸÖÿπÿ™ÿ®ÿ± Ÿà ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€å ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ.
- **ÿ®ÿ±ÿ±ÿ≥€å ⁄©€åŸÅ€åÿ™**: Ÿàÿ∂ÿπ€åÿ™ ÿ¢ŸÜŸÑÿß€åŸÜ ÿ®ŸàÿØŸÜ Ÿà Ÿæ€åŸÜ⁄Ø Ÿáÿ± Ÿæÿ±Ÿà⁄©ÿ≥€å ÿ®ÿ±ÿ±ÿ≥€å ŸÖ€å‚Äåÿ¥ŸàÿØ.
- **ÿ≠ÿ∞ŸÅ ÿ™⁄©ÿ±ÿßÿ±€å‚ÄåŸáÿß**: Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ÿ™⁄©ÿ±ÿßÿ±€å ÿ®Ÿá‚ÄåÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ≠ÿ∞ŸÅ ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ.
- **ÿÆÿ±Ÿàÿ¨€å ŸÖÿ±ÿ™ÿ®**: Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿØÿ± ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ÿ¨ÿØÿß⁄ØÿßŸÜŸá (`SOCKS5.txt`, `SOCKS4.txt`, `HTTPS.txt`) ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ.
- **ÿ±ÿßÿ®ÿ∑ ⁄©ÿßÿ±ÿ®ÿ±€å ÿ≠ÿ±ŸÅŸá‚Äåÿß€å**: ÿßÿ∑ŸÑÿßÿπÿßÿ™ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿØÿ± README ÿ®ÿß ÿ¨ÿØŸàŸÑ‚ÄåŸáÿß€å ÿ≤€åÿ®ÿß ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ.

## üöÄ Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿß
- üåê **Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å ÿßÿ≤ ŸÖŸÜÿßÿ®ÿπ ŸÖÿ™ŸÜŸàÿπ**: ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€å Ÿæÿ±Ÿà⁄©ÿ≥€å ÿßÿ≤ ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ŸÖÿ™ŸÜ€å Ÿà JSON.
- ‚ö° **ÿßÿ¨ÿ±ÿß€å ŸÖŸàÿßÿ≤€å**: ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ThreadPoolExecutor ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å ÿ≥ÿ±€åÿπ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß.
- üìä **ÿßŸÜÿØÿßÿ≤Ÿá‚Äå⁄Ø€åÿ±€å Ÿæ€åŸÜ⁄Ø**: ŸÜŸÖÿß€åÿ¥ Ÿæ€åŸÜ⁄Ø Ÿáÿ± Ÿæÿ±Ÿà⁄©ÿ≥€å ÿ®ÿ±ÿß€å ÿßŸÜÿ™ÿÆÿßÿ® ÿ®Ÿáÿ™ÿ±€åŸÜ‚ÄåŸáÿß.
- üóë **ÿ≠ÿ∞ŸÅ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ÿ∫€åÿ±ŸÅÿπÿßŸÑ**: ŸÅŸÇÿ∑ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ÿ¢ŸÜŸÑÿß€åŸÜ ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ.
- üïí **ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å ÿÆŸàÿØ⁄©ÿßÿ±**: ÿßÿ¨ÿ±ÿß Ÿáÿ± ÿ±Ÿàÿ≤ ÿ≥ÿßÿπÿ™ 2:30 ÿ®Ÿá ŸàŸÇÿ™ ÿß€åÿ±ÿßŸÜ.

## üìã Ÿæ€åÿ¥‚ÄåŸÜ€åÿßÿ≤Ÿáÿß
ÿ®ÿ±ÿß€å ÿßÿ¨ÿ±ÿß€å ÿß€åŸÜ Ÿæÿ±Ÿà⁄òŸá ÿ®Ÿá ŸÖŸàÿßÿ±ÿØ ÿ≤€åÿ± ŸÜ€åÿßÿ≤ ÿØÿßÿ±€åÿØ:
- üêç **Ÿæÿß€åÿ™ŸàŸÜ 3.9 €åÿß ÿ®ÿßŸÑÿßÿ™ÿ±**
- üì¶ **⁄©ÿ™ÿßÿ®ÿÆÿßŸÜŸá‚ÄåŸáÿß€å ŸÖŸàÿ±ÿØ ŸÜ€åÿßÿ≤**:
  - `requests`
  - `pytz`
  - `jdatetime`
- ŸÜÿµÿ® Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß:
  ```bash
  pip install -r requirements.txt

## üõ† ŸÜÿ≠ŸàŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá
1. **ÿØÿßŸÜŸÑŸàÿØ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß**:
   - ŸÅÿß€åŸÑ‚ÄåŸáÿß€å `SOCKS5.txt`, `SOCKS4.txt`, `HTTPS.txt`, Ÿà `requirements.txt` ÿ±ÿß ÿßÿ≤ [ÿ®ÿÆÿ¥ Releases](https://github.com/Argh94/ProxyProwler/releases) ÿØÿßŸÜŸÑŸàÿØ ⁄©ŸÜ€åÿØ.
2. **ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿØÿ± ÿßÿ®ÿ≤ÿßÿ±Ÿáÿß**:
   - Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿ±ÿß ÿØÿ± ⁄©ŸÑÿß€åŸÜÿ™‚ÄåŸáÿß€å ÿÆŸàÿØ (ŸÖÿ´ŸÑ ŸÖÿ±Ÿàÿ±⁄Øÿ±Ÿáÿß €åÿß ÿßÿ®ÿ≤ÿßÿ±Ÿáÿß€å ÿ¥ÿ®⁄©Ÿá) Ÿàÿßÿ±ÿØ ⁄©ŸÜ€åÿØ.
3. **ÿßÿ¨ÿ±ÿß€å ÿØÿ≥ÿ™€å**:
   - Workflow ÿ±ÿß ÿßÿ≤ ÿ™ÿ® **Actions** ÿØÿ± GitHub ÿßÿ¨ÿ±ÿß ⁄©ŸÜ€åÿØ ÿ™ÿß Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å ÿ¥ŸàŸÜÿØ.

## üåç ŸÖŸÜÿßÿ®ÿπ Ÿæÿ±Ÿà⁄©ÿ≥€å
ProxyProwler ÿßÿ≤ ŸÖŸÜÿßÿ®ÿπ ŸÖÿπÿ™ÿ®ÿ± ÿ≤€åÿ± ÿ®ÿ±ÿß€å ÿ¨ŸÖÿπ‚Äåÿ¢Ÿàÿ±€å Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜÿØ:

| ŸÖŸÜÿ®ÿπ | ŸÜŸàÿπ Ÿæÿ±Ÿà⁄©ÿ≥€å | ŸÑ€åŸÜ⁄© |
|------|-------------|------|
| OpenProxyList | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/roosterkid/openproxylist) |
| KangProxy | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/officialputuid/KangProxy) |
| Proxifly | SOCKS5, SOCKS4, HTTPS | [GitHub](https://github.com/proxifly/free-proxy-list) |
| Hookzof | SOCKS5 | [GitHub](https://github.com/hookzof/socks5_list) |
| TheSpeedX | SOCKS5, SOCKS4 | [GitHub](https://github.com/TheSpeedX/SOCKS-List) |
| Jetkai | SOCKS5 | [GitHub](https://github.com/jetkai/proxy-list) |
| ProxyScrape | SOCKS5 | [API](https://api.proxyscrape.com) |

## üìà ŸÜŸÖŸàŸÜŸá Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß
ÿ¨ÿØŸàŸÑ‚ÄåŸáÿß€å ÿ≤€åÿ± ŸÜŸÖŸàŸÜŸá‚Äåÿß€å ÿßÿ≤ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ŸÅÿπÿßŸÑ (ÿ≠ÿØÿß⁄©ÿ´ÿ± €µ ŸÜŸÖŸàŸÜŸá ÿ®ÿ±ÿß€å Ÿáÿ± ŸÜŸàÿπ) ÿ±ÿß ŸáŸÖÿ±ÿßŸá ÿ®ÿß Ÿæ€åŸÜ⁄Ø ÿ¢ŸÜ‚ÄåŸáÿß ŸÜŸÖÿß€åÿ¥ ŸÖ€å‚ÄåÿØŸáŸÜÿØ:

{table_rows}

> **üí° ŸÜ⁄©ÿ™Ÿá**: ÿ®ÿ±ÿß€å ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ŸÑ€åÿ≥ÿ™ ⁄©ÿßŸÖŸÑ Ÿà ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿßÿå ŸÅÿß€åŸÑ‚ÄåŸáÿß€å ŸÖÿ±ÿ®Ÿàÿ∑Ÿá ÿ±ÿß ÿßÿ≤ [ÿ®ÿÆÿ¥ Releases](https://github.com/Argh94/ProxyProwler/releases) ÿØÿßŸÜŸÑŸàÿØ ⁄©ŸÜ€åÿØ.

## üõ† ÿπ€åÿ®‚Äå€åÿßÿ®€å
ÿß⁄Øÿ± ÿ®ÿß ŸÖÿ¥⁄©ŸÑ€å ŸÖŸàÿßÿ¨Ÿá ÿ¥ÿØ€åÿØÿå ÿß€åŸÜ ŸÖÿ±ÿßÿ≠ŸÑ ÿ±ÿß ÿßŸÖÿ™ÿ≠ÿßŸÜ ⁄©ŸÜ€åÿØ:
- **ÿÆÿ∑ÿß€å ŸÜÿµÿ® ⁄©ÿ™ÿßÿ®ÿÆÿßŸÜŸá‚ÄåŸáÿß**: ŸÖÿ∑ŸÖÿ¶ŸÜ ÿ¥Ÿà€åÿØ ŸÅÿß€åŸÑ `requirements.txt` ÿ±ÿß ÿßÿ≤ Releases ÿØÿßŸÜŸÑŸàÿØ ⁄©ÿ±ÿØŸá‚Äåÿß€åÿØ.
- **ÿπÿØŸÖ ÿ™ŸàŸÑ€åÿØ ŸÅÿß€åŸÑ‚ÄåŸáÿß€å Ÿæÿ±Ÿà⁄©ÿ≥€å**: ŸÑÿß⁄Ø‚ÄåŸáÿß€å GitHub Actions ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ ÿ™ÿß ÿ®ÿ®€åŸÜ€åÿØ ÿ¢€åÿß ŸÖŸÜÿßÿ®ÿπ Ÿæÿ±Ÿà⁄©ÿ≥€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ Ÿáÿ≥ÿ™ŸÜÿØ.
- **Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ÿ∫€åÿ±ŸÅÿπÿßŸÑ**: ŸÖŸÜÿßÿ®ÿπ Ÿæÿ±Ÿà⁄©ÿ≥€å ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ŸÖŸàŸÇÿ™ÿßŸã ÿßÿ≤ ÿØÿ≥ÿ™ÿ±ÿ≥ ÿÆÿßÿ±ÿ¨ ÿ¥ŸàŸÜÿØ. ŸÖŸÜÿßÿ®ÿπ ÿ¨ÿØ€åÿØ ÿ±ÿß ÿ®Ÿá ŸÑ€åÿ≥ÿ™ `proxy_urls` ÿßÿ∂ÿßŸÅŸá ⁄©ŸÜ€åÿØ.

## ü§ù ŸÖÿ¥ÿßÿ±⁄©ÿ™ ÿØÿ± Ÿæÿ±Ÿà⁄òŸá
ŸÖÿß ÿßÿ≤ ŸÖÿ¥ÿßÿ±⁄©ÿ™ ÿ¥ŸÖÿß ÿßÿ≥ÿ™ŸÇÿ®ÿßŸÑ ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ! ÿ®ÿ±ÿß€å ⁄©ŸÖ⁄© ÿ®Ÿá ÿ®Ÿáÿ®ŸàÿØ ProxyProwler:
1. ŸÖÿÆÿ≤ŸÜ ÿ±ÿß ŸÅŸàÿ±⁄© ⁄©ŸÜ€åÿØ.
2. ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿÆŸàÿØ (ŸÖÿ´ŸÑ ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ ŸÖŸÜÿßÿ®ÿπ ÿ¨ÿØ€åÿØ €åÿß ÿ®Ÿáÿ®ŸàÿØ ⁄©ÿØ) ÿ±ÿß ÿßÿπŸÖÿßŸÑ ⁄©ŸÜ€åÿØ.
3. Pull Request ÿ®ŸÅÿ±ÿ≥ÿ™€åÿØ.
ÿß€åÿØŸá‚ÄåŸáÿß€å ÿ¨ÿØ€åÿØ €åÿß ⁄Øÿ≤ÿßÿ±ÿ¥ ÿ®ÿß⁄Ø‚ÄåŸáÿß ÿ±ÿß ÿßÿ≤ ÿ∑ÿ±€åŸÇ **Issues** ÿØÿ± GitHub ŸÖÿ∑ÿ±ÿ≠ ⁄©ŸÜ€åÿØ.

## üìú ŸÑÿß€åÿ≥ŸÜÿ≥
ÿß€åŸÜ Ÿæÿ±Ÿà⁄òŸá ÿ™ÿ≠ÿ™ **[ŸÑÿß€åÿ≥ŸÜÿ≥ MIT](https://opensource.org/licenses/MIT)** ŸÖŸÜÿ™ÿ¥ÿ± ÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿ¥ŸÖÿß ÿ¢ÿ≤ÿßÿØ€åÿØ ⁄©Ÿá ÿßÿ≤ ⁄©ÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØÿå ÿ™ÿ∫€å€åÿ± ÿØŸá€åÿØ Ÿà ÿ®Ÿá ÿßÿ¥ÿ™ÿ±ÿß⁄© ÿ®⁄Øÿ∞ÿßÿ±€åÿØ.

---

**üöÄ ProxyProwler** - ÿ®ÿß ŸÇÿØÿ±ÿ™ ÿ®Ÿá ÿØŸÜÿ®ÿßŸÑ Ÿæÿ±Ÿà⁄©ÿ≥€å‚ÄåŸáÿß€å ŸÅÿπÿßŸÑ!  
ÿ®ÿ±ÿß€å ÿ≥ŸàÿßŸÑÿßÿ™ €åÿß Ÿæ€åÿ¥ŸÜŸáÿßÿØÿßÿ™ÿå ÿØÿ± GitHub ÿ®ÿß ŸÖÿß ÿØÿ± ÿ™ŸÖÿßÿ≥ ÿ®ÿßÿ¥€åÿØ.

        filename = "README.md"
        with open(filename, 'w', encoding='utf-8') as file:
            file.write(readme_content)
        logging.info(f"Successfully updated {filename}")
        if os.path.exists(filename):
            logging.info(f"Confirmed: {filename} exists in the repository root")
        else:
            logging.error(f"Failed: {filename} was not created")
except Exception as e:
    logging.error(f"Error updating {filename}: {e}")

if __name__ == "__main__":
    proxy_urls = {
        'SOCKS5': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS5_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks5/socks5.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks5/data.txt",
            "https://raw.githubusercontent.com/hookzof/socks5_list/master/tg/socks.json",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt",
            "https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-socks5.txt",
            "https://api.proxyscrape.com/v3/free-proxy-list/get?request=displayproxies&proxytype=socks5"
        ],
        'SOCKS4': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS4_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks4/socks4.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks4/data.txt",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks4.txt"
        ],
        'HTTPS': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/https/https.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/http/data.txt"
        ]
    }
    proxy_type = sys.argv[1] if len(sys.argv) > 1 else None
    proxy_dict = {}

    if proxy_type and proxy_type in proxy_urls:
        all_proxies = []
        for url in proxy_urls[proxy_type]:
            proxies = fetch_proxies_from_url(url, proxy_type)
            all_proxies.extend(proxies)
        proxy_dict[proxy_type] = all_proxies
        save_proxies_to_file(all_proxies, proxy_type)
    else:
        for proxy_type, urls in proxy_urls.items():
            all_proxies = []
            for url in urls:
                proxies = fetch_proxies_from_url(url, proxy_type)
                all_proxies.extend(proxies)
            proxy_dict[proxy_type] = all_proxies
            save_proxies_to_file(all_proxies, proxy_type)

    logging.debug(f"Final proxy_dict: {proxy_dict}")
    update_readme(proxy_dict)
